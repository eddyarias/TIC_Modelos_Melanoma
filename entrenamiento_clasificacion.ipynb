{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def17278",
   "metadata": {
    "id": "def17278"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from baseCode.dataloaders.data_augmentation import data_aug_selector\n",
    "from baseCode.models.classification import load_model\n",
    "from baseCode.dataloaders.Image_Dataset import Image_Dataset\n",
    "from baseCode.utils.tensorboard import start_tensorboard\n",
    "from baseCode.utils.manual_stop import check_stop_training, set_stop_training, get_training_status \n",
    "from baseCode.train_classification import train_loop, validation_loop, compute_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b34eb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81b34eb6",
    "outputId": "0118b3f8-e01d-4a71-9c25-4fe6ed9f36df"
   },
   "outputs": [],
   "source": [
    "# Configuraci√≥n de par√°metros\n",
    "backbone = 'swin_v2_b'  # Cambia por el backbone que desees\n",
    "weights = 'imagenet'  # 'none' o 'imagenet'\n",
    "num_classes = 2\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo seleccionado: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de TensorBoard\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_dir = f'runs/training_{backbone}_{timestamp}'\n",
    "writer = SummaryWriter(log_dir)\n",
    "tensorboard_process = start_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JIqvMccxViRU",
   "metadata": {
    "id": "JIqvMccxViRU"
   },
   "outputs": [],
   "source": [
    "metadata_path = '../DataTIC/bcn20000_metadata_2025-10-19.csv'\n",
    "images_dir = '../DataTIC/ISIC-images'\n",
    "df = pd.read_csv(metadata_path)\n",
    "df = df[df['diagnosis_1'].isin(['Benign', 'Malignant'])]\n",
    "df = df[df['isic_id'].notna()]\n",
    "df = df.head(100).copy()\n",
    "df['filename'] = df['isic_id'].apply(lambda x: f\"{x}.jpg\")\n",
    "df['filepath'] = df['filename'].apply(lambda x: os.path.join(images_dir, x))\n",
    "df = df[df['filepath'].apply(os.path.exists)]\n",
    "image_label_pairs = list(zip(df['filepath'], df['diagnosis_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6acb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear objeto args m√≠nimo para reutilizar data_aug_selector e Image_Dataset\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.da_library = 'torchvision'  # o 'albumentations'\n",
    "        self.da_level = 'heavy'          # light | medium | heavy\n",
    "        self.img_size = 224\n",
    "        self.backbone = backbone\n",
    "        self.weights = weights\n",
    "        self.batch_size = batch_size\n",
    "        self.jobs = 0  # workers\n",
    "args = Args()\n",
    "\n",
    "# Generar split train/val y construir listas temporales en memoria\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[label_col])\n",
    "print(f\"Split -> Train: {len(train_df)} | Val: {len(val_df)}\")\n",
    "\n",
    "# Map labels a √≠ndices ya definidos en label2idx\n",
    "train_lines = [f\"{row['filepath']} {label2idx[row[label_col]]}\" for _, row in train_df.iterrows()]\n",
    "val_lines   = [f\"{row['filepath']} {label2idx[row[label_col]]}\" for _, row in val_df.iterrows()]\n",
    "\n",
    "# Guardar listas temporales para compatibilidad con read_list\n",
    "os.makedirs('temp_lists', exist_ok=True)\n",
    "train_list_path = 'temp_lists/train.txt'\n",
    "val_list_path   = 'temp_lists/validation.txt'\n",
    "with open(train_list_path, 'w') as f: f.write('\\n'.join(train_lines))\n",
    "with open(val_list_path, 'w') as f: f.write('\\n'.join(val_lines))\n",
    "print(f\"Listas guardadas en temp_lists/\")\n",
    "\n",
    "# Construir transform de Data Augmentation seg√∫n args\n",
    "a_transform = data_aug_selector(args)\n",
    "\n",
    "# Instanciar datasets usando Image_Dataset\n",
    "train_dataset = Image_Dataset(train_list_path, args=args, transform=a_transform)\n",
    "val_dataset   = Image_Dataset(val_list_path, img_size=(args.img_size,args.img_size), transform=None)\n",
    "print(f\"Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)} | Clases: {train_dataset.n_classes}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Batches -> Train: {len(train_loader)} | Val: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wk8tblb0o6go",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk8tblb0o6go",
    "outputId": "0daea744-8052-443e-8f1b-cce6852a22a1"
   },
   "outputs": [],
   "source": [
    "# Mapear los labels a √≠ndices num√©ricos para clasificaci√≥n\n",
    "label2idx = {label: idx for idx, label in enumerate(sorted(df['diagnosis_1'].unique()))}\n",
    "label_col = 'diagnosis_1'\n",
    "print('Diccionario de labels:', label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6d1e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afa6d1e5",
    "outputId": "ed74519a-9c27-4829-b3aa-38690ba85057"
   },
   "outputs": [],
   "source": [
    "model = load_model(backbone, weights, num_classes)\n",
    "model = model.to(device)\n",
    "print_layers(model)\n",
    "print(f\"Modelo {backbone} cargado con {num_classes} clases y pesos: {weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890eff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_basecode(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, writer=None):\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    control_file_path = 'baseCode/assets/training_control.json'\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(f\"\\n√âpoca {epoch}/{num_epochs}\")\n",
    "        # Train\n",
    "        train_loss, train_acc = train_loop(model, device, train_loader, criterion, optimizer)\n",
    "        # Validation\n",
    "        val_loss, val_acc = validation_loop(model, device, val_loader, criterion)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        # TensorBoard\n",
    "        if writer:\n",
    "            writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "            writer.add_scalar('Train/Accuracy', train_acc, epoch)\n",
    "            writer.add_scalar('Val/Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val/Accuracy', val_acc, epoch)\n",
    "            writer.add_scalar('Train/LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "            if epoch % 5 == 0:\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.requires_grad:\n",
    "                        writer.add_histogram(f'Params/{name}', param, epoch)\n",
    "                        if param.grad is not None:\n",
    "                            writer.add_histogram(f'Grads/{name}', param.grad, epoch)\n",
    "\n",
    "        print(f\"Entrenamiento - Loss: {train_loss:.5f}, Acc: {train_acc:.3%}\")\n",
    "        print(f\"Validaci√≥n   - Loss: {val_loss:.5f}, Acc: {val_acc:.3%}\")\n",
    "\n",
    "        if check_stop_training(control_file_path):\n",
    "            print(f\"üõë Parada manual activada tras la √©poca {epoch}\")\n",
    "            break\n",
    "\n",
    "    if writer:\n",
    "        writer.close()\n",
    "        print(f\"üìä Logs almacenados en: {writer.log_dir}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a12cfb",
   "metadata": {
    "id": "36a12cfb"
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo usando bucles de baseCode (Image_Dataset + data_aug_selector)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"üöÄ Iniciando entrenamiento con baseCode y Image_Dataset...\")\n",
    "print(f\"üìä Logs TensorBoard en: {log_dir}\")\n",
    "print(f\"üìÅ Train samples: {len(train_loader.dataset)} | Val samples: {len(val_loader.dataset)}\")\n",
    "\n",
    "history = train_with_basecode(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, writer)\n",
    "\n",
    "# Guardar el modelo final\n",
    "model_path = f\"modelo_{backbone}_{timestamp}.pth\"\n",
    "os.makedirs('modelos_guardados', exist_ok=True)\n",
    "final_model_path = os.path.join('modelos_guardados', f\"{backbone}_{timestamp}.pth\")\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"‚úÖ Modelo final guardado en {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1e495",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "75d1e495",
    "outputId": "7e82989c-4b8c-407d-f9a7-5f7c5ebf8dd8"
   },
   "outputs": [],
   "source": [
    "# Visualizar resultados del entrenamiento\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history['train_loss'], marker='o', label='Train Loss')\n",
    "plt.plot(history['val_loss'], marker='o', label='Val Loss')\n",
    "plt.title('P√©rdida (Loss)')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history['train_acc'], marker='o', label='Train Acc')\n",
    "plt.plot(history['val_acc'], marker='o', label='Val Acc')\n",
    "plt.title('Precisi√≥n (Accuracy)')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97392eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ RESETEAR CONTROL PARA PR√ìXIMO ENTRENAMIENTO\n",
    "print(\"üîÑ Reseteando control para pr√≥ximo entrenamiento...\")\n",
    "set_stop_training(False)  # Asegurar que est√© en False para pr√≥ximos entrenamientos\n",
    "get_training_status()     # Verificar el estado final"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
